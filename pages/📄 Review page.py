import os
import json
import streamlit as st
from glob import glob
from langchain.document_loaders import ArxivLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.retrievers import EnsembleRetriever
from langchain_core.runnables import RunnablePassthrough
from src.utils import load_docs_from_jsonl
from langchain.chat_models.openai import ChatOpenAI
from langchain.prompts import PromptTemplate
import time


class ReviewPage:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=250,
            chunk_overlap=50,
            length_function=len,
            is_separator_regex=False,
        )
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

        # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        if "retriever" not in st.session_state:
            st.session_state.retriever = None
        if "paper_retriever" not in st.session_state:
            st.session_state.paper_retriever = None
        if "youtube_retriever" not in st.session_state:
            st.session_state.youtube_retriever = None

    def load_markdown(self, title):
        if os.path.exists(f"./data/review_markdown/{title}.md"):
            with open(f"./data/review_markdown/{title}.md", "r") as f:
                return f.read()
        else:
            return f"## {title} Review\n\n"

    def save_markdown(self, md, title):
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs("./data/review_markdown", exist_ok=True)
        with open(f"./data/review_markdown/{title}.md", "w") as f:
            f.write(md)

    def create_vector_db(self, db_file_name, docs):
        if os.path.exists(db_file_name):
            db = FAISS.load_local(
                db_file_name,
                self.embeddings,
                allow_dangerous_deserialization=True,
            )
        else:
            docs = self.text_splitter.split_documents(docs)
            db = FAISS.from_documents(docs, self.embeddings)
            db.save_local(db_file_name)

        return db.as_retriever()

    def create_arxiv_vector_db(self, arxiv_id):
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text("ë…¼ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            progress_bar.progress(10)

            arxiv_loader = ArxivLoader(arxiv_id)
            docs = arxiv_loader.load()

            status_text.text("ë…¼ë¬¸ì„ ë¶„ì„í•˜ëŠ” ì¤‘...")
            progress_bar.progress(30)

            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs("./data/vector_db", exist_ok=True)
            db_file_name = f"./data/vector_db/{arxiv_id}_paper_pdf"

            status_text.text("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
            progress_bar.progress(60)

            retriever = self.create_vector_db(db_file_name, docs)

            status_text.text("ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            progress_bar.progress(100)
            time.sleep(0.5)  # ì ì‹œ ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ

            progress_bar.empty()
            status_text.empty()

            return retriever
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"RAG ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def create_youtube_vector_db(self, db_file_name_youtube, docs, video_name):
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text("YouTube ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...")
            progress_bar.progress(30)

            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(db_file_name_youtube), exist_ok=True)

            status_text.text("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
            progress_bar.progress(60)

            youtube_retriever = self.create_vector_db(db_file_name_youtube, docs)

            status_text.text("ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            progress_bar.progress(100)
            time.sleep(0.5)  # ì ì‹œ ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ

            progress_bar.empty()
            status_text.empty()

            st.session_state.youtube_retriever = youtube_retriever
            st.success(f"{video_name} ìŠ¤í¬ë¦½íŠ¸ì˜ RAGê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.experimental_rerun()  # í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë²„íŠ¼ ìƒíƒœ ì—…ë°ì´íŠ¸

            return youtube_retriever
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"YouTube RAG ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def answer_question(self, question):
        language = st.session_state.language
        result = self.rag_chain.invoke(question)
        with st.container(border=True):
            st.markdown(f"**ì§ˆë¬¸**: {question}")
            st.markdown(f"**ë‹µë³€ ({language})**: {result.content}")

    def format_docs(self, docs):
        return "\n\n".join(doc.page_content for doc in docs)

    def setup(self):
        st.set_page_config(
            page_title="Review Paper",
            page_icon="ğŸ“„",
        )

        if "paper_data" not in st.session_state or st.session_state.paper_data is None:
            st.error("ë…¼ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í™ˆí˜ì´ì§€ì—ì„œ ë…¼ë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()

        df = st.session_state.paper_data["df"]
        paper_title = df["Title"].values[0]
        abstract = df["Summary"].values[0]
        arxiv_id = df["arxiv_id"].values[0]

        # ì–¸ì–´ ì„ íƒ (ê¸°ë³¸ê°’ì€ í•œêµ­ì–´)
        if "language" not in st.session_state:
            st.session_state.language = "í•œêµ­ì–´"

        st.markdown(f"# {paper_title}")

        # ìƒë‹¨ ì„¤ì • ì„¹ì…˜
        with st.container(border=True):
            col_settings = st.columns([1, 1])
            with col_settings[0]:
                selected_language = st.selectbox(
                    "ì‘ë‹µ ì–¸ì–´",
                    ["í•œêµ­ì–´", "English", "æ—¥æœ¬èª", "ä¸­æ–‡"],
                    index=["í•œêµ­ì–´", "English", "æ—¥æœ¬èª", "ä¸­æ–‡"].index(
                        st.session_state.language
                    ),
                )
                st.session_state.language = selected_language

            with col_settings[1]:
                # ì–¸ì–´ ì½”ë“œ ë§¤í•‘
                language_code_map = {
                    "í•œêµ­ì–´": "ko",
                    "English": "en",
                    "æ—¥æœ¬èª": "ja",
                    "ä¸­æ–‡": "zh",
                }
                language_code = language_code_map[selected_language]

        # 1. ì§ˆë¬¸ ê¸°ëŠ¥ì„ ìƒë‹¨ì— ë°°ì¹˜
        llm = ChatOpenAI(model="gpt-4o")
        qa_prompt_template = """
        You are an expert in summarizing and explaining complex information. Use the provided information from both academic papers and video reviews to answer the user's question comprehensively. Ensure that your answer is clear, concise, and based on the retrieved documents.
        
        IMPORTANT: You must respond in {language}.

        Provided Information:
        {context}

        Question:
        {question}

        Answer (in {language}):
        """
        qa_prompt = PromptTemplate(
            template=qa_prompt_template,
            input_variables=["context", "question", "language"],
        )

        # RAG ë²„íŠ¼ì„ ìƒë‹¨ì— ë°°ì¹˜
        col_rag1, col_rag2 = st.columns([1, 1])

        # Paper RAG ë²„íŠ¼ì€ ì´ë¯¸ ìƒì„±ëœ ê²½ìš° í‘œì‹œí•˜ì§€ ì•ŠìŒ
        paper_rag_exists = (
            "paper_retriever" in st.session_state
            and st.session_state.paper_retriever is not None
        )

        if not paper_rag_exists:
            with col_rag1:
                if st.button("Paper RAG ìƒì„±", use_container_width=True):
                    with st.spinner("RAGë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        retriever = self.create_arxiv_vector_db(arxiv_id)
                        if retriever:
                            st.session_state.paper_retriever = retriever
                            st.success("Paper RAGê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.experimental_rerun()  # í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë²„íŠ¼ ìƒíƒœ ì—…ë°ì´íŠ¸
        else:
            with col_rag1:
                st.success("Paper RAGê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # RAG ìƒíƒœ í‘œì‹œ
        if (
            "paper_retriever" in st.session_state
            and "youtube_retriever" in st.session_state
            and st.session_state.paper_retriever is not None
            and st.session_state.youtube_retriever is not None
        ):
            retriever = EnsembleRetriever(
                retrievers=[
                    st.session_state.paper_retriever,
                    st.session_state.youtube_retriever,
                ],
                weights=[0.6, 0.4],
            )
            st.session_state.retriever = retriever
            st.success("Paper retrieverì™€ Youtube retrieverë¥¼ ì•™ìƒë¸”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        elif (
            "paper_retriever" in st.session_state
            and st.session_state.paper_retriever is not None
        ):
            st.info("Paper retrieverê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state.retriever = st.session_state.paper_retriever
        elif (
            "youtube_retriever" in st.session_state
            and st.session_state.youtube_retriever is not None
        ):
            st.info("Youtube retrieverê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state.retriever = st.session_state.youtube_retriever
        else:
            st.session_state.retriever = None
            st.warning("ì•„ì§ í™œì„±í™”ëœ retrieverê°€ ì—†ìŠµë‹ˆë‹¤. RAGë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")

        if st.session_state.retriever is not None:
            try:
                self.rag_chain = (
                    {
                        "context": st.session_state.retriever | self.format_docs,
                        "question": RunnablePassthrough(),
                        "language": lambda _: language_code,
                    }
                    | qa_prompt
                    | llm
                )

                st.markdown("## ì§ˆë¬¸í•˜ê¸°")
                q_ = st.chat_input("ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”:")
                if q_:
                    with st.spinner(f"{selected_language}ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        self.answer_question(q_)
            except Exception as e:
                st.error(f"RAG ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.session_state.retriever = None

        # 2. ë¦¬ë·° ì‘ì„± ë¶€ë¶„
        st.markdown("## ë¦¬ë·° ì‘ì„±")
        col_1, col_2 = st.columns([1, 1], gap="large")

        with col_1:
            md = self.load_markdown(paper_title)
            md = st.text_area("Reviewë¥¼ ìœ„í•œ Markdownì„ ì…ë ¥í•˜ì„¸ìš”: ", md, height=500)

            if st.button("Markdown ì €ì¥"):
                self.save_markdown(md, paper_title)
                st.success("Markdownì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        with col_2:
            st.write(md)

        # 3. YouTube ìŠ¤í¬ë¦½íŠ¸ ì„¹ì…˜
        youtube_trans_list = glob(
            f"./data/youtube_audio/{arxiv_id}/{paper_title}/*json"
        )

        if youtube_trans_list:
            st.markdown("## YouTube ìŠ¤í¬ë¦½íŠ¸")
            with st.container(border=True):
                for i, trans_path in enumerate(youtube_trans_list):
                    try:
                        docs = load_docs_from_jsonl(trans_path)
                        trans = "".join([doc.page_content for doc in docs])
                        video_name = trans_path.split("/")[-2]
                        st.expander(video_name, expanded=False).markdown(trans)

                        # ì´ë¯¸ YouTube RAGê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        db_file_name_youtube = (
                            f"./data/vector_db/{video_name}_youtube_trans"
                        )
                        youtube_rag_exists = (
                            "youtube_retriever" in st.session_state
                            and st.session_state.youtube_retriever is not None
                            and os.path.exists(db_file_name_youtube)
                        )

                        docs = self.text_splitter.split_documents(docs)

                        if not youtube_rag_exists:
                            st.button(
                                "YouTube RAG ìƒì„±",
                                on_click=self.create_youtube_vector_db,
                                args=(db_file_name_youtube, docs, video_name),
                                key=f"youtube_rag_{i}",
                            )
                        else:
                            st.success(f"{video_name} RAGê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


if __name__ == "__main__":
    page = ReviewPage()
    page.setup()
